= Neo4j Streaming Data Integrations User Guide v{docs-version}
:toc: left
:experimental:
:toclevels: 10
:sectid:
:sectlinks:

== Motivation

Many user and customers want to integrate Kafka and other streaming solutions with Neo4j.
Either to ingest data into the graph from other sources.
Or to send update events (change data capture - CDC) to the event log for later consumption.

This extension was developed to satisfy all these use-cases and more to come.

The project is composed of several parts:

* Neo4j Streams Procedure: a procedure to send a payload to a topic
* Neo4j Streams Producer: a transaction event handler events that sends data to a Kafka topic
* Neo4j Streams Consumer: a Neo4j application that ingest data from Kafka topics into Neo4j via templated Cypher Statements
* Kafka-Connect Plugin: a plugin for the Confluent Platform that allows to ingest data into Neo4j, from Kafka topics, via Cypher queries.

== Installation

Download the latest release jar from https://github.com/neo4j-contrib/neo4j-streams/releases/latest

Copy it into `$NEO4J_HOME/plugins` and configure the relevant connections.

The minimal setup in your `neo4j.conf` is:

----
kafka.zookeeper.connect=localhost:2181
kafka.bootstrap.servers=localhost:9092
----

For each module there are additional configs that are explained in the individual sections.


== Build locally

----
mvn clean install
----

1. Copy `<project_dir>/target/neo4j-streams-<VERSION>.jar` into `$NEO4J_HOME/plugins`
2. Restart Neo4j


include::producer/index.adoc[]

include::consumer/index.adoc[]

include::procedures/index.adoc[]

include::docker/index.adoc[]

include::kafka-connect/index.adoc[]